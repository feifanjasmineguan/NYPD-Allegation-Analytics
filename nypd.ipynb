{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "#### Goal: predict the outcome of an allegation based on selected features\n",
    "* This is a classification problem: I will use selected features about allegations to predict the final outcome, which is a categorical variable.\n",
    "\n",
    "#### Target variable: \"outcome_description\". \n",
    "* I want to explore whether police complaints are handled with fairness and this feature is the best variable to reflect that. I want to explore whether certain conditions of the allegation would result in different allegation outcomes.\n",
    "    * I will transform the \"outcome_description\" variable to a binary classification.\n",
    "    * If outcome == 1 --> the accused police officer is arrested/summoned/other.\n",
    "    * If outcome == 0 --> no arrest made or summons issued\n",
    "    \n",
    "#### Evaluation metric: F-1 Score\n",
    "* In this model, simple accuracy is not enough\n",
    "* In evaluating whether FN or FP are more detrimental, I decided that: letting a police officer with misconduct remain in force for more unjust police action is worse than the inconvenience caused by investigating police with proper conduct. Recall measures the proportion of positives correctly identified and penalize FN.\n",
    "    * However, simply focusing on the FN is not enough. Out of all the ones classified as positive (should be disciplined), we also want to make sure that we're not classifying too many good officers as needing discipline. That will diverge resources on actual police work and cause complaints within the department. \n",
    "    * Therefore I chose F-1 score to balance out the FP and FN and assess the model on its ability to predict bad officers while not inconveniencing too many good ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "#### Data Exploring:\n",
    "* Imputing NaN values:\n",
    "    * For quantitative variables: mos_age_incident and complainant_age_incident, I imputed the NaN values with the mean of the ages\n",
    "    * For categorical variables: mos_ethnicity, most_gender, complainant_ethnicity, complainant_gender and fado_type, I imputed the NaN values with the most commonly appeared categories. \n",
    "    * I decided to use mean and most commonly used category because they encompass the most relatively representative value of each categories.\n",
    "* Transforming outcome column\n",
    "    * The outcome I want to predict is the outcome of allegation. However, since the allegation_description columns encompasses many different types of allegation outcome, I decided to just separate them into actions taken vs. no actions taken.\n",
    "    * If the outcome contains \"No arrest\", it means that the allegation didn't go through, and I will represent it with a classification 0.\n",
    "    * For any other outcomes, there are certain actions taken against the accused, whether that be arrested, summoned or investigated, and I will represent it with a classification 1.\n",
    "    \n",
    "#### Feature:\n",
    "* The 3 main features I chose for the baseline models is: allegation\n",
    "    * The main purpose of this baseline model is to explore whether specific allegations are easier to get out of or not. \n",
    "    * I used a OneHotEncoder() to transform this categorical variable. \n",
    "\n",
    "#### Choice of Classifier\n",
    "* DecisionTreeClassifier\n",
    "    * I chose DecisionTreeClassifier with a default max_depth as the baseline model classifier. \n",
    "    * I chose DecisionTree because the tree structure allows each add-on feature to sway or determine the result of the classification.\n",
    "    \n",
    "#### Interpret F-1 Score\n",
    "* The resulting F-1 score from the baseline model is approximately 0.72.\n",
    "    * This number indicates the balance between FP and FN. \n",
    "    * Since the baseline model only includes allegation of the officer and doesn't consider any features of the complainant. I will further develop my model with more features and specially engineered features. \n",
    "    * This is also the specific allegation instead of the top-level category of allegation. The allegation being so specific could result in overfitting. Therefore in developing my final model, I will use fado_type, which is the more top-level type of allegation, to allow more generalization within the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model\n",
    "#### Feature Engineering\n",
    "* is_same_ethnicity\n",
    "    * I want to investigate whether the police and complainant having different ethnicity will impact the outcome of allegation because of the racial disparities in the police system\n",
    "    * This new column is a boolean column that indicates whether the police and complainant have the same ethnicity\n",
    "* age_difference --- quantitative\n",
    "    * A younger complainant against an older officer will likely be taken less seriously than vice versa because of seniority construct. Therefore I want to investigate whether age difference is correlated to the result of the allegation. \n",
    "    * This column is obtained by subtracting complainant_age_incidence from mos_age_incident. \n",
    "\n",
    "#### Final Model Features\n",
    "* The baseline model only covered allegation reasons, which doesn't incorporate any information on the officer and complainant. \n",
    "* Therefore for the final model, I'm using complainant gender, officer gender, whether officer and complainant are the same ethnicity, high level allegation type, rank of officer at the incident and age difference.\n",
    "* OneHotEncoder\n",
    "    * mos_gender, complainant_gender: The gender of officer and complainant will likely play an impact on the result of allegation. For example, a female complainant against a male officer might be harder to resolve than vice versa.\n",
    "    * fado_type: This is the high level category of allegation. Based on the seriousness of the allegation, and investigation might get different attention from law enforcement, therefore resulting in different outcomes.\n",
    "* FunctionTransformer\n",
    "    * rank_incident: After looking up the official police ranking of United States, I created a helper funtion to assign numbers to officer ranking, giving high level ranks more weight than low rank officers. My assumption is that higher ranked officers might have more ways to get out of an allegation than low rank officers. Therefore I used a function transformer to give weights to this variable.\n",
    "* Pass Through\n",
    "    * Boolean: is_same_ethnicity\n",
    "        * This is the engineered feature indicating whether officer and complainant are of the same ethnicity.\n",
    "    * Quantitative: age_difference\n",
    "        * This is the engineered feature indicating the age difference between officer and complainant. \n",
    "\n",
    "\n",
    "#### Final Model Pipleline\n",
    "* Classifier: RandomForestClassifier\n",
    "    * RandomForestClassifier fits data on varies subsets of the dataset and takes the average for better prediction accuracy. \n",
    "        * Since we do have a lot of variables and uncertainties in the dataset, I decided to use this classifer to best average out uncertainties.\n",
    "* Pipeline: \n",
    "    * Column Transformer: OneHotEncoder for categorical variables, FunctionTransformer for rank at incident, pass through boolean variable is_same_ethnicity and quantitative variable age_difference.\n",
    "    * Regressor: RandomForestClassifier with max_depth of 7.\n",
    "* Interpreting F-1 Score:\n",
    "    * The average f1 score has drastically improved to around 0.76. Which indicates that this model can better balance FN and FP to prevent inconveniencing the innocent but also make sure the guilty are penalized.\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Evaluation\n",
    "#### Criteria\n",
    "* is_same_ethnicity\n",
    "    * I want to explore whether the model is biased based on whether police and complainant have the same ethnicity.\n",
    "    * 22.12% of the cases have two sides of the same ethnicity, therefore we have a class imbalance problem.\n",
    "    * The following process and the result of the inference test shows that this model is not biased against the is_same_ethnicity criteria.\n",
    "    \n",
    "#### Process\n",
    "* Obtain observed value:\n",
    "    * I grouped the data by is_same_ethnicity, applied a lambda function to obtain the f1 score of each group and obtained the absolute difference between the two groups.\n",
    "    * Observed value --- 0.014239836133925432\n",
    "    * The observed value is relatively very small. However, in order to truly show that the model genralizes, I will use the following iteration mechanism to show fairness.\n",
    "* Hypothesis (Permutation) Test\n",
    "    * Null Hypothesis: the model performs equally well for those cases of the same ethnicity and those without.\n",
    "    * Alternative Hypothesis: the model performs differently for those with the same ethnicity and without.\n",
    "    * Significant level: 0.01\n",
    "    * Iterative Process:\n",
    "        * For each iteration, I shuffled the is_same_ethnicity label and repeated the process to obtain observed value. \n",
    "        * I appended all the sampled f1_scores into a list\n",
    "        * I counted the number of f1_scores that are greater than the observed value, took the average and obtained the p-value\n",
    "\n",
    "#### Interpretation\n",
    "* Pval = 0.526\n",
    "    * The obtained pval of 0.526 is way greater than the significant level, which means that we have enough evidence to show that our model performs fairly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pandas.util.testing as tm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # Higher resolution figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset\n",
    "nypd_file = os.path.join('data', 'allegations.csv')\n",
    "nypd = pd.read_csv(nypd_file)\n",
    "# imputing for NaN values\n",
    "# create binary classifier \"is_penalized\" from \"outcome_description\" \n",
    "nypd[\"rank_incident\"] = nypd[\"rank_incident\"].fillna(nypd[\"rank_incident\"].value_counts().idxmax())\n",
    "nypd[\"mos_age_incident\"] = nypd[\"mos_age_incident\"].fillna(nypd[\"mos_age_incident\"].mean())\n",
    "nypd[\"complainant_age_incident\"] = nypd[\"complainant_age_incident\"].fillna(nypd[\"complainant_age_incident\"].mean())\n",
    "nypd[\"mos_ethnicity\"] = nypd[\"mos_ethnicity\"].fillna(nypd[\"mos_ethnicity\"].value_counts().idxmax())\n",
    "nypd[\"mos_gender\"] = nypd[\"mos_gender\"].fillna(nypd[\"mos_gender\"].value_counts().idxmax())\n",
    "nypd[\"complainant_ethnicity\"] = nypd[\"complainant_ethnicity\"].fillna(nypd[\"complainant_ethnicity\"].value_counts().idxmax())\n",
    "nypd[\"complainant_gender\"] = nypd[\"complainant_gender\"].fillna(nypd[\"complainant_gender\"].value_counts().idxmax())\n",
    "nypd[\"not_arrested\"] = nypd[\"outcome_description\"].str.contains(\"No arrest\")\n",
    "def replace_outcome(row):\n",
    "    if row == True:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "nypd[\"is_penalized\"]= nypd[\"not_arrested\"].apply(replace_outcome)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_mos_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>command_now</th>\n",
       "      <th>shield_no</th>\n",
       "      <th>complaint_id</th>\n",
       "      <th>month_received</th>\n",
       "      <th>year_received</th>\n",
       "      <th>month_closed</th>\n",
       "      <th>year_closed</th>\n",
       "      <th>...</th>\n",
       "      <th>complainant_gender</th>\n",
       "      <th>complainant_age_incident</th>\n",
       "      <th>fado_type</th>\n",
       "      <th>allegation</th>\n",
       "      <th>precinct</th>\n",
       "      <th>contact_reason</th>\n",
       "      <th>outcome_description</th>\n",
       "      <th>board_disposition</th>\n",
       "      <th>not_arrested</th>\n",
       "      <th>is_penalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10004</td>\n",
       "      <td>Jonathan</td>\n",
       "      <td>Ruiz</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>8409</td>\n",
       "      <td>42835</td>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "      <td>Failure to provide RTKA card</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Report-domestic dispute</td>\n",
       "      <td>No arrest made or summons issued</td>\n",
       "      <td>Substantiated (Command Lvl Instructions)</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10007</td>\n",
       "      <td>John</td>\n",
       "      <td>Sears</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>5952</td>\n",
       "      <td>24601</td>\n",
       "      <td>11</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>...</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Discourtesy</td>\n",
       "      <td>Action</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Moving violation</td>\n",
       "      <td>Moving violation summons issued</td>\n",
       "      <td>Substantiated (Charges)</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_mos_id first_name last_name command_now  shield_no  complaint_id  \\\n",
       "0          10004   Jonathan      Ruiz     078 PCT       8409         42835   \n",
       "1          10007       John     Sears     078 PCT       5952         24601   \n",
       "\n",
       "   month_received  year_received  month_closed  year_closed  ...  \\\n",
       "0               7           2019             5         2020  ...   \n",
       "1              11           2011             8         2012  ...   \n",
       "\n",
       "  complainant_gender complainant_age_incident           fado_type  \\\n",
       "0             Female                     38.0  Abuse of Authority   \n",
       "1               Male                     26.0         Discourtesy   \n",
       "\n",
       "                     allegation precinct           contact_reason  \\\n",
       "0  Failure to provide RTKA card     78.0  Report-domestic dispute   \n",
       "1                        Action     67.0         Moving violation   \n",
       "\n",
       "                outcome_description                         board_disposition  \\\n",
       "0  No arrest made or summons issued  Substantiated (Command Lvl Instructions)   \n",
       "1   Moving violation summons issued                   Substantiated (Charges)   \n",
       "\n",
       "  not_arrested is_penalized  \n",
       "0         True            0  \n",
       "1        False            1  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nypd.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 12, 12, 12])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nypd[[\"fado_type\", \"month_closed\"]].groupby(\"fado_type\").max()[\"month_closed\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7230643846780765"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train - test split\n",
    "nypd[\"allegation\"] = nypd[\"allegation\"].fillna(nypd[\"allegation\"].value_counts().idxmax())\n",
    "bX = nypd[[\"allegation\"]]\n",
    "by = nypd[\"is_penalized\"]\n",
    "bX_train, bX_test, by_train, by_test = train_test_split(bX, by, test_size=0.3)\n",
    "\n",
    "# ColumnTransformer\n",
    "nom_trans = [\"allegation\"]\n",
    "nom_transform = OneHotEncoder(handle_unknown = \"ignore\")\n",
    "preproc = ColumnTransformer(transformers=[('nominal_extraction', nom_transform, nom_trans)], remainder='passthrough')\n",
    "base_pl = Pipeline(steps=[('preprocessor', preproc), ('classifier', DecisionTreeClassifier())])\n",
    "base_pl.fit(bX_train, by_train)\n",
    "base_preds = base_pl.predict(bX_test)\n",
    "b_f1 = metrics.f1_score(by_test, base_preds)\n",
    "b_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2212063073325739"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ordinal: FunctionTransformer for \"rank_incident\"\n",
    "def helper(df):\n",
    "    def transform_rank(rank):\n",
    "        if rank == \"Police Officer\": return 1\n",
    "        elif rank == \"Detective\": return 2\n",
    "        elif rank == \"Sergeant\": return 3\n",
    "        elif rank == \"Lieutenant\": return 4\n",
    "        elif rank == \"Captain\": return 5\n",
    "        elif rank == \"Deputy Inspector\": return 6\n",
    "        elif rank == \"Inspector\": return 7\n",
    "        elif rank == \"Chiefs and other ranks\": return 8\n",
    "        else: return 0\n",
    "    return df[\"rank_incident\"].apply(transform_rank).values.reshape(-1,1)\n",
    "\n",
    "# binary: same or different ethnicity\n",
    "nypd[\"is_same_ethnicity\"] = (nypd[\"mos_ethnicity\"] == nypd[\"complainant_ethnicity\"])\n",
    "# quantitative: the age difference between police & complainant\n",
    "nypd[\"age_difference\"] = nypd[\"mos_age_incident\"] - nypd[\"complainant_age_incident\"]\n",
    "nypd[\"is_same_ethnicity\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nypd['rank_incident']\n",
    "# def rank_helper(row):\n",
    "#     return row.fillna(nypd[\"rank_incident\"].value_counts().idxmax())\n",
    "# rank_transformer = FunctionTransformer(rank_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7607223476297967"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd model: engineered features\n",
    "import sklearn.preprocessing as pp\n",
    "X = nypd[[\"mos_gender\",\"complainant_gender\", \"is_same_ethnicity\", \"fado_type\", \"rank_incident\", \"age_difference\"]]\n",
    "y = nypd.is_penalized\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "rank_trans = [\"rank_incident\"]\n",
    "# rank_transformation = Pipeline(steps=[\n",
    "#     ('intenc', pp.OrdinalEncoder()),  # converts to int\n",
    "#     ('onehot', pp.OneHotEncoder())     # output from Ordinal becomes input to OneHot\n",
    "# ])\n",
    "rank_transformation = FunctionTransformer(helper, validate = False)\n",
    "ohe_trans = [\"mos_gender\", \"complainant_gender\",\"fado_type\"]\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "preproc = ColumnTransformer(transformers = [(\"ohe\", ohe, ohe_trans),(\"transform_rank\", rank_transformation, rank_trans)], remainder = \"passthrough\")\n",
    "pl = Pipeline(steps = [(\"preprocessor\", preproc), (\"classifier\", RandomForestClassifier(max_depth = 7, min_samples_leaf = 2, min_samples_split = 5))])\n",
    "pl.fit(X_train, y_train)\n",
    "preds = pl.predict(X_test)\n",
    "f1 = metrics.f1_score(y_test, preds)\n",
    "f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'classifier__max_depth': [2,5,7,13,18,None], \n",
    "    'classifier__min_samples_split':[2,5,10,15,20],\n",
    "    'classifier__min_samples_leaf':[2,7,10,15,20]\n",
    "}\n",
    "grid_search = GridSearchCV(pl, parameters, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_param = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__max_depth': None,\n",
       " 'classifier__min_samples_leaf': 2,\n",
       " 'classifier__min_samples_split': 10}"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.011923789832406828, 0.524)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "parity = X_test\n",
    "parity[\"predicted\"] = preds\n",
    "parity[\"y_test\"] = y_test\n",
    "obs = parity.groupby(\"is_same_ethnicity\").apply(lambda x: metrics.f1_score(x.y_test, x.predicted)).diff().abs().iloc[-1]\n",
    "stats  = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    s = (\n",
    "        parity[['is_same_ethnicity', 'predicted', 'y_test']]\n",
    "        .assign(is_same_ethnicity=parity.is_same_ethnicity.sample(frac=1.0, replace=False).reset_index(drop=True))\n",
    "        .groupby('is_same_ethnicity')\n",
    "        .apply(lambda x: metrics.f1_score(x.y_test, x.predicted))\n",
    "        .diff().abs()\n",
    "        .iloc[-1]\n",
    "    )\n",
    "    stats.append(s)\n",
    "pval = (obs >= pd.Series(stats)).mean()\n",
    "obs, pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
